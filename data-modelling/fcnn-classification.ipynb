{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Neural Network - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 20:15:57.484900: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import requests\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "full_data = pd.read_csv('f1_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_model(num_features, units=(128, 64), activation='relu', dropout_rate=0.0):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units[0], activation=activation, input_shape=(num_features,)),\n",
    "        tf.keras.layers.Dense(units[1], activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')  # Adjusted to 1 unit for binary classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using formuladata api\n",
    "\n",
    "def get_location_details(location):\n",
    "    url = 'https://formuladataapi.pythonanywhere.com/api/f1/circuit_data'\n",
    "    filters = {}\n",
    "    filters['location'] = location\n",
    "    response = requests.get(url, params=filters)\n",
    "    data = response.json()\n",
    "    try:\n",
    "      latitude = data[0]['latitude']\n",
    "      longitude = data[0]['longitude']\n",
    "      circuit_length = float(data[0]['circuit_length'][0:3])\n",
    "    except:\n",
    "      return None\n",
    "    return [latitude, longitude, circuit_length]\n",
    "\n",
    "\n",
    "def get_fp_details(driver, season, round):\n",
    "    url = 'https://formuladataapi.pythonanywhere.com/api/f1'\n",
    "    filters = {}\n",
    "    filters['driver_name'] = driver\n",
    "    filters['round'] = round\n",
    "    filters['season'] = season\n",
    "    response = requests.get(url, params=filters)\n",
    "    data = response.json()\n",
    "    try:\n",
    "      fp1 = int(data[0]['fp1_position'])\n",
    "    except:\n",
    "      fp1 = None\n",
    "    try:\n",
    "      fp2 = int(data[0]['fp2_position'])\n",
    "    except:\n",
    "      fp2 = None\n",
    "    try:\n",
    "      fp3 = int(data[0]['fp3_position'])\n",
    "    except:\n",
    "      fp3 = None\n",
    "    return [fp1, fp2, fp3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_results_with_fp(map, season, round, location, weather, XX, model, fps):\n",
    "    race_results = {}\n",
    "    weather_dict = {'dry':0, \"cloudy\":1, \"wet\":2}\n",
    "    latitude = get_location_details(location)[0]\n",
    "    longitude = get_location_details(location)[1]\n",
    "    circuit_length = get_location_details(location)[2]\n",
    "\n",
    "    for driver, team in map.items():\n",
    "        datapoint = [0]*XX.shape[1]\n",
    "        datapoint[0] = season\n",
    "        datapoint[1] = round\n",
    "        datapoint[2] = weather_dict[weather]\n",
    "        try:\n",
    "            datapoint[3] = int(fps[driver][0])\n",
    "        except:\n",
    "            datapoint[3] = 20\n",
    "        try:\n",
    "            datapoint[4] = int(fps[driver][1])\n",
    "        except:\n",
    "            datapoint[4] = 20\n",
    "        try:\n",
    "            datapoint[5] = int(fps[driver][2])\n",
    "        except:\n",
    "            datapoint[5] = 20\n",
    "        datapoint[6] = circuit_length\n",
    "        datapoint[7] = latitude\n",
    "        datapoint[8] = longitude\n",
    "\n",
    "        loc = location.lower().replace(' ', '_')\n",
    "        location_index = XX.columns.get_loc(f'location_{loc}')\n",
    "        datapoint[location_index] = 1\n",
    "    \n",
    "        driver_index = XX.columns.get_loc(f'driver_name_{driver}')\n",
    "        team_index = XX.columns.get_loc(f'constructor_name_{team}')\n",
    "        datapoint[driver_index] = 1\n",
    "        datapoint[team_index] = 1\n",
    "\n",
    "        df = pd.DataFrame([datapoint], columns=XX.columns)\n",
    "        test_prediction = model.predict(df ,verbose=0)\n",
    "        race_results[driver] = test_prediction[0][0]\n",
    "    sorted_results = sorted(race_results.items(), key=lambda x: x[1], reverse = True)\n",
    "    sorted_results = collections.OrderedDict(sorted_results)\n",
    "    return sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_team_mapping = {\n",
    "    'max_verstappen': 'red_bull_racing',\n",
    "    'fernando_alonso': 'aston_martin',\n",
    "    'lewis_hamilton': 'mercedes',\n",
    "    'charles_leclerc': 'ferrari',\n",
    "    'carlos_sainz': 'ferrari',\n",
    "    'sergio_perez': 'red_bull_racing',\n",
    "    'alexander_albon': 'williams',\n",
    "    'esteban_ocon': 'aston_martin',\n",
    "    'lance_stroll': 'aston_martin',\n",
    "    'valtteri_bottas': 'alfa_romeo',\n",
    "    'oscar_piastri': 'mclaren',\n",
    "    'pierre_gasly': 'renault',\n",
    "    'lando_norris': 'mclaren',\n",
    "    'yuki_tsunoda': 'toro_rosso',\n",
    "    'nico_hulkenberg': 'haas',\n",
    "    'zhou_guanyu': 'alfa_romeo',\n",
    "    'kevin_magnussen': 'haas',\n",
    "    'nyck_de_vries': 'toro_rosso',\n",
    "    'george_russell': 'mercedes',\n",
    "    'logan_sargeant': 'williams'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_verstappen': [1, 1, 8], 'fernando_alonso': [4, 10, 3], 'lewis_hamilton': [12, 15, 5], 'charles_leclerc': [5, None, 1], 'carlos_sainz': [7, 2, 6], 'sergio_perez': [2, 4, 14], 'alexander_albon': [3, 3, 2], 'esteban_ocon': [6, 13, 16], 'lance_stroll': [9, 6, 13], 'valtteri_bottas': [15, 16, 18], 'oscar_piastri': [10, 9, 17], 'pierre_gasly': [13, 8, 4], 'lando_norris': [8, 14, 12], 'yuki_tsunoda': [16, 18, 10], 'nico_hulkenberg': [20, 7, 19], 'zhou_guanyu': [18, 11, 20], 'kevin_magnussen': [19, 17, 15], 'nyck_de_vries': [11, 19, 11], 'george_russell': [14, 12, 9], 'logan_sargeant': [17, 5, 7]}\n"
     ]
    }
   ],
   "source": [
    "fps = {}\n",
    "for driver, _ in driver_team_mapping.items():\n",
    "    drivers = driver.split('_')\n",
    "    for d in range(len(drivers)):\n",
    "        drivers[d] = drivers[d][0].upper() + drivers[d][1:]\n",
    "    driver_parsed = ' '.join(drivers)\n",
    "    fps[driver] = get_fp_details(driver_parsed, 2023, 10)\n",
    "\n",
    "print(fps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Race Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (12659, 416) (12659,)\n",
      "Testing data shape: (3165, 416) (3165,)\n"
     ]
    }
   ],
   "source": [
    "race_data = full_data.iloc[:]\n",
    "race_data[\"in_top_5\"] = race_data['race_finishing_position'].apply(lambda x: 1 if x<=5 else 0)\n",
    "race_data = race_data.drop([\"grid_position\", \"has_fastest_lap\",\"race_laps_completed\",\"points\", \"fastest_lap_position\", \"race_finishing_position\"], axis = 1)\n",
    "\n",
    "# 2021: 14744\n",
    "\n",
    "X = race_data.drop('in_top_5', axis=1)  \n",
    "y = race_data['in_top_5']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n",
    "num_features = X_train.shape[1]\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "396/396 [==============================] - 2s 1ms/step - loss: 2.8945\n",
      "Epoch 2/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4655\n",
      "Epoch 3/100\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.4519\n",
      "Epoch 4/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4381\n",
      "Epoch 5/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4234\n",
      "Epoch 6/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4221\n",
      "Epoch 7/100\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.4161\n",
      "Epoch 8/100\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.4033\n",
      "Epoch 9/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4031\n",
      "Epoch 10/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3999\n",
      "Epoch 11/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3977\n",
      "Epoch 12/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3980\n",
      "Epoch 13/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4020\n",
      "Epoch 14/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4002\n",
      "Epoch 15/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3932\n",
      "Epoch 16/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3914\n",
      "Epoch 17/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3859\n",
      "Epoch 18/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3879\n",
      "Epoch 19/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3826\n",
      "Epoch 20/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3878\n",
      "Epoch 21/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3877\n",
      "Epoch 22/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3858\n",
      "Epoch 23/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3830\n",
      "Epoch 24/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3829\n",
      "Epoch 25/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3796\n",
      "Epoch 26/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3782\n",
      "Epoch 27/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3767\n",
      "Epoch 28/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3743\n",
      "Epoch 29/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3730\n",
      "Epoch 30/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3736\n",
      "Epoch 31/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3705\n",
      "Epoch 32/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3745\n",
      "Epoch 33/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3731\n",
      "Epoch 34/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3736\n",
      "Epoch 35/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3750\n",
      "Epoch 36/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3725\n",
      "Epoch 37/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3752\n",
      "Epoch 38/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3681\n",
      "Epoch 39/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3687\n",
      "Epoch 40/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3689\n",
      "Epoch 41/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3673\n",
      "Epoch 42/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3636\n",
      "Epoch 43/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3633\n",
      "Epoch 44/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3669\n",
      "Epoch 45/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3649\n",
      "Epoch 46/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3656\n",
      "Epoch 47/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3654\n",
      "Epoch 48/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3648\n",
      "Epoch 49/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3652\n",
      "Epoch 50/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3618\n",
      "Epoch 51/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3667\n",
      "Epoch 52/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3633\n",
      "Epoch 53/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3631\n",
      "Epoch 54/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3638\n",
      "Epoch 55/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3616\n",
      "Epoch 56/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3602\n",
      "Epoch 57/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3612\n",
      "Epoch 58/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3626\n",
      "Epoch 59/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3619\n",
      "Epoch 60/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3598\n",
      "Epoch 61/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3599\n",
      "Epoch 62/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3624\n",
      "Epoch 63/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3605\n",
      "Epoch 64/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3608\n",
      "Epoch 65/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3591\n",
      "Epoch 66/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3611\n",
      "Epoch 67/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3603\n",
      "Epoch 68/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3595\n",
      "Epoch 69/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3605\n",
      "Epoch 70/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3564\n",
      "Epoch 71/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3582\n",
      "Epoch 72/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3604\n",
      "Epoch 73/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3634\n",
      "Epoch 74/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3581\n",
      "Epoch 75/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3611\n",
      "Epoch 76/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3589\n",
      "Epoch 77/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3607\n",
      "Epoch 78/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3572\n",
      "Epoch 79/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3545\n",
      "Epoch 80/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3586\n",
      "Epoch 81/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3550\n",
      "Epoch 82/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3566\n",
      "Epoch 83/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3569\n",
      "Epoch 84/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3559\n",
      "Epoch 85/100\n",
      "396/396 [==============================] - 4s 10ms/step - loss: 0.3569\n",
      "Epoch 86/100\n",
      "396/396 [==============================] - 4s 9ms/step - loss: 0.3607\n",
      "Epoch 87/100\n",
      "396/396 [==============================] - 3s 7ms/step - loss: 0.3540\n",
      "Epoch 88/100\n",
      "396/396 [==============================] - 3s 8ms/step - loss: 0.3577\n",
      "Epoch 89/100\n",
      "396/396 [==============================] - 3s 8ms/step - loss: 0.3565\n",
      "Epoch 90/100\n",
      "396/396 [==============================] - 2s 6ms/step - loss: 0.3578\n",
      "Epoch 91/100\n",
      "396/396 [==============================] - 3s 7ms/step - loss: 0.3543\n",
      "Epoch 92/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3539\n",
      "Epoch 93/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3535\n",
      "Epoch 94/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3564\n",
      "Epoch 95/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3580\n",
      "Epoch 96/100\n",
      "396/396 [==============================] - 2s 6ms/step - loss: 0.3551\n",
      "Epoch 97/100\n",
      "396/396 [==============================] - 2s 6ms/step - loss: 0.3527\n",
      "Epoch 98/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3522\n",
      "Epoch 99/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3555\n",
      "Epoch 100/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3528\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.3667\n",
      "99/99 [==============================] - 1s 4ms/step\n",
      "Accuracy: 0.7772511848341233\n"
     ]
    }
   ],
   "source": [
    "race_model = create_classification_model(num_features, (64, 32), 'relu', 0.1)\n",
    "race_model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "accuracy = race_model.evaluate(X_test, y_test)\n",
    "predictions = race_model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_verstappen 0.79\n",
      "alexander_albon 0.66\n",
      "sergio_perez 0.64\n",
      "carlos_sainz 0.59\n",
      "lewis_hamilton 0.56\n",
      "fernando_alonso 0.54\n",
      "charles_leclerc 0.46\n",
      "george_russell 0.40\n",
      "pierre_gasly 0.31\n",
      "logan_sargeant 0.29\n",
      "oscar_piastri 0.27\n",
      "lando_norris 0.26\n",
      "lance_stroll 0.13\n",
      "esteban_ocon 0.02\n",
      "valtteri_bottas 0.01\n",
      "nico_hulkenberg 0.01\n",
      "kevin_magnussen 0.00\n",
      "yuki_tsunoda 0.00\n",
      "nyck_de_vries 0.00\n",
      "zhou_guanyu 0.00\n"
     ]
    }
   ],
   "source": [
    "results_race = get_race_results_with_fp(driver_team_mapping, 2023, 10, 'Great Britain', 'cloudy', X_test, race_model, fps)\n",
    "arr_race = []\n",
    "\n",
    "for key, val in results_race.items():\n",
    "    arr_race.append((key,\"{:.2f}\".format(float(val))))\n",
    "\n",
    "\n",
    "for item in arr_race:\n",
    "    print(item[0], item[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Qualifying Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (12659, 416) (12659,)\n",
      "Testing data shape: (3165, 416) (3165,)\n"
     ]
    }
   ],
   "source": [
    "quali_data = full_data.iloc[:]\n",
    "quali_data[\"in_top_5\"] = quali_data['grid_position'].apply(lambda x: 1 if x<=5 else 0)\n",
    "quali_data = quali_data.drop([\"grid_position\", \"has_fastest_lap\",\"race_laps_completed\",\"points\", \"fastest_lap_position\", \"race_finishing_position\"], axis = 1)\n",
    "\n",
    "# 2021: 14744\n",
    "\n",
    "X = quali_data.drop('in_top_5', axis=1)  \n",
    "y = quali_data['in_top_5']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n",
    "num_features = X_train.shape[1]\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "396/396 [==============================] - 2s 2ms/step - loss: 2.9287\n",
      "Epoch 2/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3875\n",
      "Epoch 3/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3716\n",
      "Epoch 4/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3651\n",
      "Epoch 5/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3436\n",
      "Epoch 6/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3457\n",
      "Epoch 7/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3553\n",
      "Epoch 8/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3561\n",
      "Epoch 9/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3489\n",
      "Epoch 10/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3470\n",
      "Epoch 11/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3383\n",
      "Epoch 12/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3321\n",
      "Epoch 13/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3323\n",
      "Epoch 14/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3391\n",
      "Epoch 15/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3295\n",
      "Epoch 16/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3286\n",
      "Epoch 17/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3235\n",
      "Epoch 18/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3191\n",
      "Epoch 19/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3265\n",
      "Epoch 20/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3146\n",
      "Epoch 21/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3159\n",
      "Epoch 22/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3129\n",
      "Epoch 23/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3183\n",
      "Epoch 24/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3168\n",
      "Epoch 25/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3130\n",
      "Epoch 26/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3164\n",
      "Epoch 27/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3055\n",
      "Epoch 28/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3146\n",
      "Epoch 29/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3097\n",
      "Epoch 30/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3107\n",
      "Epoch 31/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3112\n",
      "Epoch 32/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3071\n",
      "Epoch 33/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3085\n",
      "Epoch 34/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3056\n",
      "Epoch 35/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3089\n",
      "Epoch 36/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3083\n",
      "Epoch 37/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3067\n",
      "Epoch 38/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3069\n",
      "Epoch 39/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3101\n",
      "Epoch 40/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2996\n",
      "Epoch 41/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3013\n",
      "Epoch 42/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2994\n",
      "Epoch 43/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3028\n",
      "Epoch 44/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3018\n",
      "Epoch 45/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2977\n",
      "Epoch 46/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3001\n",
      "Epoch 47/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3005\n",
      "Epoch 48/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3006\n",
      "Epoch 49/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2962\n",
      "Epoch 50/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2982\n",
      "Epoch 51/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2957\n",
      "Epoch 52/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2982\n",
      "Epoch 53/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2963\n",
      "Epoch 54/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2920\n",
      "Epoch 55/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2950\n",
      "Epoch 56/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.2968\n",
      "Epoch 57/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2909\n",
      "Epoch 58/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2925\n",
      "Epoch 59/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2900\n",
      "Epoch 60/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2956\n",
      "Epoch 61/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2908\n",
      "Epoch 62/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2934\n",
      "Epoch 63/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2969\n",
      "Epoch 64/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2867\n",
      "Epoch 65/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2918\n",
      "Epoch 66/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2953\n",
      "Epoch 67/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2872\n",
      "Epoch 68/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2887\n",
      "Epoch 69/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2913\n",
      "Epoch 70/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2859\n",
      "Epoch 71/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2886\n",
      "Epoch 72/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2886\n",
      "Epoch 73/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2882\n",
      "Epoch 74/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2883\n",
      "Epoch 75/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2873\n",
      "Epoch 76/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2915\n",
      "Epoch 77/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2905\n",
      "Epoch 78/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2832\n",
      "Epoch 79/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2881\n",
      "Epoch 80/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2873\n",
      "Epoch 81/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2870\n",
      "Epoch 82/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2862\n",
      "Epoch 83/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2842\n",
      "Epoch 84/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2857\n",
      "Epoch 85/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2878\n",
      "Epoch 86/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2835\n",
      "Epoch 87/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2901\n",
      "Epoch 88/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2819\n",
      "Epoch 89/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2818\n",
      "Epoch 90/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2819\n",
      "Epoch 91/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2847\n",
      "Epoch 92/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2836\n",
      "Epoch 93/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2843\n",
      "Epoch 94/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2825\n",
      "Epoch 95/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2818\n",
      "Epoch 96/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2795\n",
      "Epoch 97/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2817\n",
      "Epoch 98/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2859\n",
      "Epoch 99/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2779\n",
      "Epoch 100/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2762\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.2843\n",
      "99/99 [==============================] - 0s 1ms/step\n",
      "Accuracy: 0.7661927330173776\n"
     ]
    }
   ],
   "source": [
    "quali_model = create_classification_model(num_features, (64, 32), 'relu', 0.1)\n",
    "quali_model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "accuracy = quali_model.evaluate(X_test, y_test)\n",
    "predictions = quali_model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_verstappen 0.90\n",
      "alexander_albon 0.86\n",
      "sergio_perez 0.80\n",
      "carlos_sainz 0.68\n",
      "lewis_hamilton 0.46\n",
      "fernando_alonso 0.42\n",
      "logan_sargeant 0.41\n",
      "charles_leclerc 0.36\n",
      "pierre_gasly 0.31\n",
      "george_russell 0.19\n",
      "lando_norris 0.14\n",
      "oscar_piastri 0.14\n",
      "lance_stroll 0.10\n",
      "nico_hulkenberg 0.02\n",
      "esteban_ocon 0.02\n",
      "valtteri_bottas 0.01\n",
      "kevin_magnussen 0.01\n",
      "nyck_de_vries 0.00\n",
      "zhou_guanyu 0.00\n",
      "yuki_tsunoda 0.00\n"
     ]
    }
   ],
   "source": [
    "results_quali = get_race_results_with_fp(driver_team_mapping, 2023, 10, 'Great Britain', 'cloudy', X_test, quali_model, fps)\n",
    "arr_quali = []\n",
    "\n",
    "for key, val in results_quali.items():\n",
    "    arr_quali.append((key,\"{:.2f}\".format(float(val))))\n",
    "\n",
    "\n",
    "for item in arr_quali:\n",
    "    print(item[0], item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fastest Lap Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (12659, 416) (12659,)\n",
      "Testing data shape: (3165, 416) (3165,)\n"
     ]
    }
   ],
   "source": [
    "fl_data = full_data.iloc[:]\n",
    "fl_data[\"in_top_5\"] = fl_data['fastest_lap_position'].apply(lambda x: 1 if x<=5 else 0)\n",
    "fl_data = fl_data.drop([\"grid_position\", \"has_fastest_lap\",\"race_laps_completed\",\"points\", \"fastest_lap_position\", \"race_finishing_position\"], axis = 1)\n",
    "\n",
    "# 2021: 14744\n",
    "\n",
    "X = fl_data.drop('in_top_5', axis=1)  \n",
    "y = fl_data['in_top_5']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n",
    "num_features = X_train.shape[1]\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "396/396 [==============================] - 2s 2ms/step - loss: 1.1790\n",
      "Epoch 2/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4426\n",
      "Epoch 3/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4487\n",
      "Epoch 4/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4368\n",
      "Epoch 5/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4292\n",
      "Epoch 6/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4261\n",
      "Epoch 7/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4330\n",
      "Epoch 8/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4255\n",
      "Epoch 9/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4229\n",
      "Epoch 10/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4207\n",
      "Epoch 11/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4228\n",
      "Epoch 12/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4214\n",
      "Epoch 13/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4199\n",
      "Epoch 14/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4189\n",
      "Epoch 15/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.4218\n",
      "Epoch 16/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4181\n",
      "Epoch 17/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4229\n",
      "Epoch 18/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4134\n",
      "Epoch 19/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4206\n",
      "Epoch 20/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4173\n",
      "Epoch 21/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4172\n",
      "Epoch 22/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4113\n",
      "Epoch 23/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4131\n",
      "Epoch 24/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4123\n",
      "Epoch 25/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4106\n",
      "Epoch 26/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4125\n",
      "Epoch 27/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4116\n",
      "Epoch 28/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4135\n",
      "Epoch 29/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4153\n",
      "Epoch 30/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4046\n",
      "Epoch 31/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4098\n",
      "Epoch 32/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4120\n",
      "Epoch 33/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4071\n",
      "Epoch 34/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4107\n",
      "Epoch 35/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4100\n",
      "Epoch 36/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4059\n",
      "Epoch 37/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4044\n",
      "Epoch 38/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4074\n",
      "Epoch 39/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4076\n",
      "Epoch 40/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4081\n",
      "Epoch 41/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4102\n",
      "Epoch 42/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4015\n",
      "Epoch 43/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4066\n",
      "Epoch 44/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4054\n",
      "Epoch 45/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4065\n",
      "Epoch 46/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4010\n",
      "Epoch 47/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4031\n",
      "Epoch 48/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4026\n",
      "Epoch 49/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4036\n",
      "Epoch 50/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4042\n",
      "Epoch 51/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3993\n",
      "Epoch 52/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4025\n",
      "Epoch 53/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3783\n",
      "Epoch 54/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3742\n",
      "Epoch 55/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3801\n",
      "Epoch 56/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3736\n",
      "Epoch 57/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3767\n",
      "Epoch 58/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3744\n",
      "Epoch 59/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3731\n",
      "Epoch 60/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3777\n",
      "Epoch 61/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3733\n",
      "Epoch 62/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3777\n",
      "Epoch 63/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3709\n",
      "Epoch 64/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3747\n",
      "Epoch 65/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3719\n",
      "Epoch 66/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3719\n",
      "Epoch 67/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3706\n",
      "Epoch 68/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3719\n",
      "Epoch 69/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3718\n",
      "Epoch 70/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3710\n",
      "Epoch 71/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3720\n",
      "Epoch 72/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3654\n",
      "Epoch 73/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3652\n",
      "Epoch 74/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3638\n",
      "Epoch 75/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3644\n",
      "Epoch 76/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3637\n",
      "Epoch 77/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3639\n",
      "Epoch 78/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3661\n",
      "Epoch 79/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3645\n",
      "Epoch 80/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3609\n",
      "Epoch 81/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3604\n",
      "Epoch 82/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3597\n",
      "Epoch 83/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3643\n",
      "Epoch 84/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3642\n",
      "Epoch 85/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3614\n",
      "Epoch 86/100\n",
      "396/396 [==============================] - 2s 6ms/step - loss: 0.3602\n",
      "Epoch 87/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3583\n",
      "Epoch 88/100\n",
      "396/396 [==============================] - 2s 6ms/step - loss: 0.3586\n",
      "Epoch 89/100\n",
      "396/396 [==============================] - 3s 7ms/step - loss: 0.3591\n",
      "Epoch 90/100\n",
      "396/396 [==============================] - 3s 8ms/step - loss: 0.3591\n",
      "Epoch 91/100\n",
      "396/396 [==============================] - 3s 8ms/step - loss: 0.3601\n",
      "Epoch 92/100\n",
      "396/396 [==============================] - 3s 8ms/step - loss: 0.3570\n",
      "Epoch 93/100\n",
      "396/396 [==============================] - 4s 10ms/step - loss: 0.3586\n",
      "Epoch 94/100\n",
      "396/396 [==============================] - 4s 10ms/step - loss: 0.3579\n",
      "Epoch 95/100\n",
      "396/396 [==============================] - 3s 7ms/step - loss: 0.3555\n",
      "Epoch 96/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3579\n",
      "Epoch 97/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3521\n",
      "Epoch 98/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3558\n",
      "Epoch 99/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3535\n",
      "Epoch 100/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3536\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.3759\n",
      "99/99 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.7772511848341233\n"
     ]
    }
   ],
   "source": [
    "fl_model = create_classification_model(num_features, (64, 32), 'relu', 0.1)\n",
    "fl_model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "accuracy = fl_model.evaluate(X_test, y_test)\n",
    "predictions = fl_model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_verstappen 0.76\n",
      "alexander_albon 0.74\n",
      "sergio_perez 0.73\n",
      "carlos_sainz 0.66\n",
      "lewis_hamilton 0.58\n",
      "logan_sargeant 0.55\n",
      "fernando_alonso 0.47\n",
      "george_russell 0.41\n",
      "charles_leclerc 0.33\n",
      "pierre_gasly 0.30\n",
      "lando_norris 0.29\n",
      "oscar_piastri 0.27\n",
      "lance_stroll 0.17\n",
      "yuki_tsunoda 0.06\n",
      "zhou_guanyu 0.05\n",
      "nico_hulkenberg 0.03\n",
      "valtteri_bottas 0.03\n",
      "kevin_magnussen 0.02\n",
      "nyck_de_vries 0.02\n",
      "esteban_ocon 0.01\n"
     ]
    }
   ],
   "source": [
    "results_fl = get_race_results_with_fp(driver_team_mapping, 2023, 10, 'Great Britain', 'cloudy', X_test, fl_model, fps)\n",
    "arr_fl = []\n",
    "\n",
    "for key, val in results_fl.items():\n",
    "    arr_fl.append((key,\"{:.2f}\".format(float(val))))\n",
    "\n",
    "\n",
    "for item in arr_fl:\n",
    "    print(item[0], item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RACE  [('max_verstappen', '0.79'), ('alexander_albon', '0.66'), ('sergio_perez', '0.64'), ('carlos_sainz', '0.59'), ('lewis_hamilton', '0.56'), ('fernando_alonso', '0.54'), ('charles_leclerc', '0.46'), ('george_russell', '0.40'), ('pierre_gasly', '0.31'), ('logan_sargeant', '0.29'), ('oscar_piastri', '0.27'), ('lando_norris', '0.26'), ('lance_stroll', '0.13'), ('esteban_ocon', '0.02'), ('valtteri_bottas', '0.01'), ('nico_hulkenberg', '0.01'), ('kevin_magnussen', '0.00'), ('yuki_tsunoda', '0.00'), ('nyck_de_vries', '0.00'), ('zhou_guanyu', '0.00')]\n",
      "........................\n",
      "QUALI [('max_verstappen', '0.90'), ('alexander_albon', '0.86'), ('sergio_perez', '0.80'), ('carlos_sainz', '0.68'), ('lewis_hamilton', '0.46'), ('fernando_alonso', '0.42'), ('logan_sargeant', '0.41'), ('charles_leclerc', '0.36'), ('pierre_gasly', '0.31'), ('george_russell', '0.19'), ('lando_norris', '0.14'), ('oscar_piastri', '0.14'), ('lance_stroll', '0.10'), ('nico_hulkenberg', '0.02'), ('esteban_ocon', '0.02'), ('valtteri_bottas', '0.01'), ('kevin_magnussen', '0.01'), ('nyck_de_vries', '0.00'), ('zhou_guanyu', '0.00'), ('yuki_tsunoda', '0.00')]\n",
      "........................\n",
      "F_LAP [('max_verstappen', '0.76'), ('alexander_albon', '0.74'), ('sergio_perez', '0.73'), ('carlos_sainz', '0.66'), ('lewis_hamilton', '0.58'), ('logan_sargeant', '0.55'), ('fernando_alonso', '0.47'), ('george_russell', '0.41'), ('charles_leclerc', '0.33'), ('pierre_gasly', '0.30'), ('lando_norris', '0.29'), ('oscar_piastri', '0.27'), ('lance_stroll', '0.17'), ('yuki_tsunoda', '0.06'), ('zhou_guanyu', '0.05'), ('nico_hulkenberg', '0.03'), ('valtteri_bottas', '0.03'), ('kevin_magnussen', '0.02'), ('nyck_de_vries', '0.02'), ('esteban_ocon', '0.01')]\n"
     ]
    }
   ],
   "source": [
    "print(\"RACE \", arr_race)\n",
    "print(\"........................\")\n",
    "print(\"QUALI\", arr_quali)\n",
    "print(\"........................\")\n",
    "print(\"F_LAP\", arr_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowjs\n",
      "  Using cached tensorflowjs-4.9.0-py3-none-any.whl (89 kB)\n",
      "Collecting tensorflow-decision-forests>=1.3.0\n",
      "  Using cached tensorflow_decision_forests-1.5.0-cp310-cp310-macosx_10_15_x86_64.whl (12.3 MB)\n",
      "Collecting importlib_resources>=5.9.0\n",
      "  Using cached importlib_resources-6.0.0-py3-none-any.whl (31 kB)\n",
      "Collecting jax>=0.3.16\n",
      "  Using cached jax-0.4.13-py3-none-any.whl\n",
      "Collecting tensorflow-hub>=0.13.0\n",
      "  Using cached tensorflow_hub-0.14.0-py2.py3-none-any.whl (90 kB)\n",
      "Collecting packaging~=20.9\n",
      "  Using cached packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: six<2,>=1.12.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflowjs) (1.16.0)\n",
      "Requirement already satisfied: tensorflow<3,>=2.12.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflowjs) (2.13.0)\n",
      "Collecting flax<0.6.3,>=0.6.2\n",
      "  Using cached flax-0.6.2-py3-none-any.whl (189 kB)\n",
      "Requirement already satisfied: numpy>=1.12 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (1.24.3)\n",
      "Collecting rich>=11.1\n",
      "  Using cached rich-13.4.2-py3-none-any.whl (239 kB)\n",
      "Collecting tensorstore\n",
      "  Using cached tensorstore-0.1.40-cp310-cp310-macosx_10_14_x86_64.whl (13.8 MB)\n",
      "Collecting optax\n",
      "  Using cached optax-0.1.5-py3-none-any.whl (164 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (4.5.0)\n",
      "Collecting PyYAML>=5.4.1\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-macosx_10_9_x86_64.whl (189 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.4/189.4 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting msgpack\n",
      "  Using cached msgpack-1.0.5-cp310-cp310-macosx_10_9_x86_64.whl (74 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.2-cp310-cp310-macosx_10_12_x86_64.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes>=0.1.0\n",
      "  Using cached ml_dtypes-0.2.0-cp310-cp310-macosx_10_9_universal2.whl (1.2 MB)\n",
      "Requirement already satisfied: scipy>=1.7 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from jax>=0.3.16->tensorflowjs) (1.11.1)\n",
      "Requirement already satisfied: opt-einsum in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from jax>=0.3.16->tensorflowjs) (3.3.0)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Downloading pyparsing-3.1.0-py3-none-any.whl (102 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (3.9.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.32.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (23.5.26)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.13.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (16.0.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (4.23.4)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.4.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.13.0)\n",
      "Requirement already satisfied: setuptools in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (58.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.56.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.3.0)\n",
      "Collecting wurlitzer\n",
      "  Using cached wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: pandas in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow-decision-forests>=1.3.0->tensorflowjs) (2.0.3)\n",
      "Requirement already satisfied: wheel in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow-decision-forests>=1.3.0->tensorflowjs) (0.40.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (2.15.1)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (0.7.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.3.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (3.4.3)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.0-cp310-cp310-macosx_10_9_x86_64.whl (243 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.6/243.6 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing>=2.0.2\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-10.0.0-cp310-cp310-macosx_10_10_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-macosx_10_9_x86_64.whl (65 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (2.8.2)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.41.0-cp310-cp310-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting chex>=0.1.5\n",
      "  Using cached chex-0.1.82-py3-none-any.whl (94 kB)\n",
      "Collecting jaxlib>=0.1.37\n",
      "  Using cached jaxlib-0.4.13-cp310-cp310-macosx_10_14_x86_64.whl (75.0 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from pandas->tensorflow-decision-forests>=1.3.0->tensorflowjs) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from pandas->tensorflow-decision-forests>=1.3.0->tensorflowjs) (2023.3)\n",
      "Collecting toolz>=0.9.0\n",
      "  Using cached toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "Collecting chex>=0.1.5\n",
      "  Using cached chex-0.1.81-py3-none-any.whl (94 kB)\n",
      "Collecting dm-tree>=0.1.5\n",
      "  Using cached dm_tree-0.1.8-cp310-cp310-macosx_10_9_x86_64.whl (115 kB)\n",
      "Collecting chex>=0.1.5\n",
      "  Using cached chex-0.1.7-py3-none-any.whl (89 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (1.26.16)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (1.3.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (3.2.2)\n",
      "Installing collected packages: msgpack, dm-tree, wurlitzer, toolz, tensorstore, tensorflow-hub, PyYAML, pyparsing, pillow, ml-dtypes, mdurl, kiwisolver, importlib_resources, fonttools, cycler, contourpy, packaging, markdown-it-py, jaxlib, jax, rich, matplotlib, chex, optax, flax, tensorflow-decision-forests, tensorflowjs\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "Successfully installed PyYAML-6.0.1 chex-0.1.7 contourpy-1.1.0 cycler-0.11.0 dm-tree-0.1.8 flax-0.6.2 fonttools-4.41.0 importlib_resources-6.0.0 jax-0.4.13 jaxlib-0.4.13 kiwisolver-1.4.4 markdown-it-py-3.0.0 matplotlib-3.7.2 mdurl-0.1.2 ml-dtypes-0.2.0 msgpack-1.0.5 optax-0.1.5 packaging-20.9 pillow-10.0.0 pyparsing-3.0.9 rich-13.4.2 tensorflow-decision-forests-1.5.0 tensorflow-hub-0.14.0 tensorflowjs-4.9.0 tensorstore-0.1.40 toolz-0.12.0 wurlitzer-3.0.3\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2 is available.\n",
      "You should consider upgrading via the '/Users/anirudhkrishna/GitHub/FormulaData/formulavenv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfjs.converters.save_keras_model(race_model, \"/Users/anirudhkrishna/GitHub/FormulaData/data-modelling/race_model/\")\n",
    "# tfjs.converters.save_keras_model(quali_model, \"/Users/anirudhkrishna/GitHub/FormulaData/data-modelling/quali_model/\")\n",
    "# tfjs.converters.save_keras_model(fl_model, \"/Users/anirudhkrishna/GitHub/FormulaData/data-modelling/fl_model/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# /Users/anirudhkrishna/GitHub/FormulaData/api/\n",
    "\n",
    "# race_model.save(\"/Users/anirudhkrishna/GitHub/FormulaData/api/race_model.h5\")\n",
    "# quali_model.save(\"/Users/anirudhkrishna/GitHub/FormulaData/api/quali_model.h5\")\n",
    "# fl_model.save(\"/Users/anirudhkrishna/GitHub/FormulaData/api/fl_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_data.iloc[-20:].to_csv(\"/Users/anirudhkrishna/GitHub/FormulaData/api/sample_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "formulakernel",
   "language": "python",
   "name": "formulakernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
