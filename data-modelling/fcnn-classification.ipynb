{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Neural Network - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 02:07:48.793468: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import requests\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "full_data = pd.read_csv('f1_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_model(num_features, units=(128, 64), activation='relu', dropout_rate=0.0):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units[0], activation=activation, input_shape=(num_features,)),\n",
    "        tf.keras.layers.Dense(units[1], activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')  # Adjusted to 1 unit for binary classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using formuladata api\n",
    "\n",
    "def get_location_details(location):\n",
    "    url = 'https://formuladataapi.pythonanywhere.com/api/f1/circuit_data'\n",
    "    filters = {}\n",
    "    filters['location'] = location\n",
    "    response = requests.get(url, params=filters)\n",
    "    data = response.json()\n",
    "    try:\n",
    "      latitude = data[0]['latitude']\n",
    "      longitude = data[0]['longitude']\n",
    "      circuit_length = float(data[0]['circuit_length'][0:3])\n",
    "    except:\n",
    "      return None\n",
    "    return [latitude, longitude, circuit_length]\n",
    "\n",
    "\n",
    "def get_fp_details(driver, season, round):\n",
    "    url = 'https://formuladataapi.pythonanywhere.com/api/f1'\n",
    "    filters = {}\n",
    "    filters['driver_name'] = driver\n",
    "    filters['round'] = round\n",
    "    filters['season'] = season\n",
    "    response = requests.get(url, params=filters)\n",
    "    data = response.json()\n",
    "    try:\n",
    "      fp1 = int(data[0]['fp1_position'])\n",
    "    except:\n",
    "      fp1 = None\n",
    "    try:\n",
    "      fp2 = int(data[0]['fp2_position'])\n",
    "    except:\n",
    "      fp2 = None\n",
    "    try:\n",
    "      fp3 = int(data[0]['fp3_position'])\n",
    "    except:\n",
    "      fp3 = None\n",
    "    return [fp1, fp2, fp3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_results_with_fp(map, season, round, location, weather, XX, model, fps):\n",
    "    race_results = {}\n",
    "    weather_dict = {'dry':0, \"cloudy\":1, \"wet\":2}\n",
    "    latitude = get_location_details(location)[0]\n",
    "    longitude = get_location_details(location)[1]\n",
    "    circuit_length = get_location_details(location)[2]\n",
    "\n",
    "    for driver, team in map.items():\n",
    "        datapoint = [0]*XX.shape[1]\n",
    "        datapoint[0] = season\n",
    "        datapoint[1] = round\n",
    "        datapoint[2] = weather_dict[weather]\n",
    "        try:\n",
    "            datapoint[3] = int(fps[driver][0])\n",
    "        except:\n",
    "            datapoint[3] = 20\n",
    "        try:\n",
    "            datapoint[4] = int(fps[driver][1])\n",
    "        except:\n",
    "            datapoint[4] = 20\n",
    "        try:\n",
    "            datapoint[5] = int(fps[driver][2])\n",
    "        except:\n",
    "            datapoint[5] = 20\n",
    "        datapoint[6] = circuit_length\n",
    "        datapoint[7] = latitude\n",
    "        datapoint[8] = longitude\n",
    "\n",
    "        loc = location.lower().replace(' ', '_')\n",
    "        location_index = XX.columns.get_loc(f'location_{loc}')\n",
    "        datapoint[location_index] = 1\n",
    "    \n",
    "        driver_index = XX.columns.get_loc(f'driver_name_{driver}')\n",
    "        team_index = XX.columns.get_loc(f'constructor_name_{team}')\n",
    "        datapoint[driver_index] = 1\n",
    "        datapoint[team_index] = 1\n",
    "\n",
    "        df = pd.DataFrame([datapoint], columns=XX.columns)\n",
    "        test_prediction = model.predict(df ,verbose=0)\n",
    "        race_results[driver] = test_prediction[0][0]\n",
    "    sorted_results = sorted(race_results.items(), key=lambda x: x[1], reverse = True)\n",
    "    sorted_results = collections.OrderedDict(sorted_results)\n",
    "    return sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_team_mapping = {\n",
    "    'max_verstappen': 'red_bull_racing',\n",
    "    'fernando_alonso': 'aston_martin',\n",
    "    'lewis_hamilton': 'mercedes',\n",
    "    'charles_leclerc': 'ferrari',\n",
    "    'carlos_sainz': 'ferrari',\n",
    "    'sergio_perez': 'red_bull_racing',\n",
    "    'alexander_albon': 'williams',\n",
    "    'esteban_ocon': 'aston_martin',\n",
    "    'lance_stroll': 'aston_martin',\n",
    "    'valtteri_bottas': 'alfa_romeo',\n",
    "    'oscar_piastri': 'mclaren',\n",
    "    'pierre_gasly': 'renault',\n",
    "    'lando_norris': 'mclaren',\n",
    "    'yuki_tsunoda': 'toro_rosso',\n",
    "    'nico_hulkenberg': 'haas',\n",
    "    'zhou_guanyu': 'alfa_romeo',\n",
    "    'kevin_magnussen': 'haas',\n",
    "    'nyck_de_vries': 'toro_rosso',\n",
    "    'george_russell': 'mercedes',\n",
    "    'logan_sargeant': 'williams'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_verstappen': [1, 1, 8], 'fernando_alonso': [4, 10, 3], 'lewis_hamilton': [12, 15, 5], 'charles_leclerc': [5, None, 1], 'carlos_sainz': [7, 2, 6], 'sergio_perez': [2, 4, 14], 'alexander_albon': [3, 3, 2], 'esteban_ocon': [6, 13, 16], 'lance_stroll': [9, 6, 13], 'valtteri_bottas': [15, 16, 18], 'oscar_piastri': [10, 9, 17], 'pierre_gasly': [13, 8, 4], 'lando_norris': [8, 14, 12], 'yuki_tsunoda': [16, 18, 10], 'nico_hulkenberg': [20, 7, 19], 'zhou_guanyu': [18, 11, 20], 'kevin_magnussen': [19, 17, 15], 'nyck_de_vries': [11, 19, 11], 'george_russell': [14, 12, 9], 'logan_sargeant': [17, 5, 7]}\n"
     ]
    }
   ],
   "source": [
    "fps = {}\n",
    "for driver, _ in driver_team_mapping.items():\n",
    "    drivers = driver.split('_')\n",
    "    for d in range(len(drivers)):\n",
    "        drivers[d] = drivers[d][0].upper() + drivers[d][1:]\n",
    "    driver_parsed = ' '.join(drivers)\n",
    "    fps[driver] = get_fp_details(driver_parsed, 2023, 10)\n",
    "\n",
    "print(fps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Race Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (12659, 416) (12659,)\n",
      "Testing data shape: (3165, 416) (3165,)\n"
     ]
    }
   ],
   "source": [
    "race_data = full_data.iloc[:]\n",
    "race_data[\"in_top_5\"] = race_data['race_finishing_position'].apply(lambda x: 1 if x<=5 else 0)\n",
    "race_data = race_data.drop([\"grid_position\", \"has_fastest_lap\",\"race_laps_completed\",\"points\", \"fastest_lap_position\", \"race_finishing_position\"], axis = 1)\n",
    "\n",
    "# 2021: 14744\n",
    "\n",
    "X = race_data.drop('in_top_5', axis=1)  \n",
    "y = race_data['in_top_5']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n",
    "num_features = X_train.shape[1]\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "396/396 [==============================] - 2s 2ms/step - loss: 3.4439\n",
      "Epoch 2/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4467\n",
      "Epoch 3/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4383\n",
      "Epoch 4/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4573\n",
      "Epoch 5/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4389\n",
      "Epoch 6/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4336\n",
      "Epoch 7/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4337\n",
      "Epoch 8/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4224\n",
      "Epoch 9/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4181\n",
      "Epoch 10/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4121\n",
      "Epoch 11/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4072\n",
      "Epoch 12/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3990\n",
      "Epoch 13/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3990\n",
      "Epoch 14/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3984\n",
      "Epoch 15/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4015\n",
      "Epoch 16/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3962\n",
      "Epoch 17/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3938\n",
      "Epoch 18/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3962\n",
      "Epoch 19/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3941\n",
      "Epoch 20/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3944\n",
      "Epoch 21/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3902\n",
      "Epoch 22/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3907\n",
      "Epoch 23/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3919\n",
      "Epoch 24/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3889\n",
      "Epoch 25/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3881\n",
      "Epoch 26/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3905\n",
      "Epoch 27/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3884\n",
      "Epoch 28/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3852\n",
      "Epoch 29/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3875\n",
      "Epoch 30/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3856\n",
      "Epoch 31/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3841\n",
      "Epoch 32/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3858\n",
      "Epoch 33/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3827\n",
      "Epoch 34/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3853\n",
      "Epoch 35/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3841\n",
      "Epoch 36/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3858\n",
      "Epoch 37/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3854\n",
      "Epoch 38/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3829\n",
      "Epoch 39/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3838\n",
      "Epoch 40/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3824\n",
      "Epoch 41/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3793\n",
      "Epoch 42/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3853\n",
      "Epoch 43/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3788\n",
      "Epoch 44/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3776\n",
      "Epoch 45/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3787\n",
      "Epoch 46/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3694\n",
      "Epoch 47/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3734\n",
      "Epoch 48/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3743\n",
      "Epoch 49/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3726\n",
      "Epoch 50/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3760\n",
      "Epoch 51/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3724\n",
      "Epoch 52/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3713\n",
      "Epoch 53/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3749\n",
      "Epoch 54/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3733\n",
      "Epoch 55/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3657\n",
      "Epoch 56/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3704\n",
      "Epoch 57/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3666\n",
      "Epoch 58/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3715\n",
      "Epoch 59/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3677\n",
      "Epoch 60/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3689\n",
      "Epoch 61/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3706\n",
      "Epoch 62/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3684\n",
      "Epoch 63/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3674\n",
      "Epoch 64/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3665\n",
      "Epoch 65/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3688\n",
      "Epoch 66/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3646\n",
      "Epoch 67/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3667\n",
      "Epoch 68/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3678\n",
      "Epoch 69/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3596\n",
      "Epoch 70/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3639\n",
      "Epoch 71/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3666\n",
      "Epoch 72/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3644\n",
      "Epoch 73/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3614\n",
      "Epoch 74/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3628\n",
      "Epoch 75/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3612\n",
      "Epoch 76/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3624\n",
      "Epoch 77/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3579\n",
      "Epoch 78/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3622\n",
      "Epoch 79/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3612\n",
      "Epoch 80/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3575\n",
      "Epoch 81/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3610\n",
      "Epoch 82/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3591\n",
      "Epoch 83/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3554\n",
      "Epoch 84/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3544\n",
      "Epoch 85/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3524\n",
      "Epoch 86/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3570\n",
      "Epoch 87/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3544\n",
      "Epoch 88/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3539\n",
      "Epoch 89/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3550\n",
      "Epoch 90/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3570\n",
      "Epoch 91/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3554\n",
      "Epoch 92/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3558\n",
      "Epoch 93/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3555\n",
      "Epoch 94/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3584\n",
      "Epoch 95/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3546\n",
      "Epoch 96/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3559\n",
      "Epoch 97/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3544\n",
      "Epoch 98/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3600\n",
      "Epoch 99/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3539\n",
      "Epoch 100/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3587\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.3651\n",
      "99/99 [==============================] - 0s 1ms/step\n",
      "Accuracy: 0.7772511848341233\n"
     ]
    }
   ],
   "source": [
    "race_model = create_classification_model(num_features, (64, 32), 'relu', 0.1)\n",
    "race_model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "accuracy = race_model.evaluate(X_test, y_test)\n",
    "predictions = race_model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_verstappen 0.78\n",
      "alexander_albon 0.70\n",
      "carlos_sainz 0.66\n",
      "lewis_hamilton 0.63\n",
      "sergio_perez 0.63\n",
      "fernando_alonso 0.51\n",
      "charles_leclerc 0.44\n",
      "george_russell 0.43\n",
      "pierre_gasly 0.30\n",
      "logan_sargeant 0.29\n",
      "oscar_piastri 0.23\n",
      "lando_norris 0.22\n",
      "lance_stroll 0.12\n",
      "esteban_ocon 0.03\n",
      "valtteri_bottas 0.02\n",
      "nico_hulkenberg 0.01\n",
      "nyck_de_vries 0.01\n",
      "yuki_tsunoda 0.01\n",
      "kevin_magnussen 0.00\n",
      "zhou_guanyu 0.00\n"
     ]
    }
   ],
   "source": [
    "results_race = get_race_results_with_fp(driver_team_mapping, 2023, 10, 'Great Britain', 'cloudy', X_test, race_model, fps)\n",
    "arr_race = []\n",
    "\n",
    "for key, val in results_race.items():\n",
    "    arr_race.append((key,\"{:.2f}\".format(float(val))))\n",
    "\n",
    "\n",
    "for item in arr_race:\n",
    "    print(item[0], item[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Qualifying Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (12659, 416) (12659,)\n",
      "Testing data shape: (3165, 416) (3165,)\n"
     ]
    }
   ],
   "source": [
    "quali_data = full_data.iloc[:]\n",
    "quali_data[\"in_top_5\"] = quali_data['grid_position'].apply(lambda x: 1 if x<=5 else 0)\n",
    "quali_data = quali_data.drop([\"grid_position\", \"has_fastest_lap\",\"race_laps_completed\",\"points\", \"fastest_lap_position\", \"race_finishing_position\"], axis = 1)\n",
    "\n",
    "# 2021: 14744\n",
    "\n",
    "X = quali_data.drop('in_top_5', axis=1)  \n",
    "y = quali_data['in_top_5']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n",
    "num_features = X_train.shape[1]\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.8279\n",
      "Epoch 2/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3696\n",
      "Epoch 3/100\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.3609\n",
      "Epoch 4/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3511\n",
      "Epoch 5/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3469\n",
      "Epoch 6/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3475\n",
      "Epoch 7/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3375\n",
      "Epoch 8/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3326\n",
      "Epoch 9/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3284\n",
      "Epoch 10/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3317\n",
      "Epoch 11/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3316\n",
      "Epoch 12/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3464\n",
      "Epoch 13/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3424\n",
      "Epoch 14/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3377\n",
      "Epoch 15/100\n",
      "396/396 [==============================] - 3s 8ms/step - loss: 0.3356\n",
      "Epoch 16/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3233\n",
      "Epoch 17/100\n",
      "396/396 [==============================] - 3s 7ms/step - loss: 0.3278\n",
      "Epoch 18/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3276\n",
      "Epoch 19/100\n",
      "396/396 [==============================] - 3s 6ms/step - loss: 0.3223\n",
      "Epoch 20/100\n",
      "396/396 [==============================] - 2s 6ms/step - loss: 0.3175\n",
      "Epoch 21/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3119\n",
      "Epoch 22/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3105\n",
      "Epoch 23/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3179\n",
      "Epoch 24/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3100\n",
      "Epoch 25/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3127\n",
      "Epoch 26/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3037\n",
      "Epoch 27/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3091\n",
      "Epoch 28/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3101\n",
      "Epoch 29/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3077\n",
      "Epoch 30/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3044\n",
      "Epoch 31/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3077\n",
      "Epoch 32/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3008\n",
      "Epoch 33/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3079\n",
      "Epoch 34/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3044\n",
      "Epoch 35/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3029\n",
      "Epoch 36/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2995\n",
      "Epoch 37/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3013\n",
      "Epoch 38/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3027\n",
      "Epoch 39/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3043\n",
      "Epoch 40/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3021\n",
      "Epoch 41/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3016\n",
      "Epoch 42/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3063\n",
      "Epoch 43/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3011\n",
      "Epoch 44/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2967\n",
      "Epoch 45/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3012\n",
      "Epoch 46/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2998\n",
      "Epoch 47/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.2955\n",
      "Epoch 48/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2988\n",
      "Epoch 49/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2958\n",
      "Epoch 50/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2966\n",
      "Epoch 51/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3026\n",
      "Epoch 52/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.2983\n",
      "Epoch 53/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2911\n",
      "Epoch 54/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2903\n",
      "Epoch 55/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2850\n",
      "Epoch 56/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2931\n",
      "Epoch 57/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2890\n",
      "Epoch 58/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2860\n",
      "Epoch 59/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2905\n",
      "Epoch 60/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2883\n",
      "Epoch 61/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2845\n",
      "Epoch 62/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2849\n",
      "Epoch 63/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2896\n",
      "Epoch 64/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2871\n",
      "Epoch 65/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.2876\n",
      "Epoch 66/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2830\n",
      "Epoch 67/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2812\n",
      "Epoch 68/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.2863\n",
      "Epoch 69/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2843\n",
      "Epoch 70/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2812\n",
      "Epoch 71/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2838\n",
      "Epoch 72/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2818\n",
      "Epoch 73/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2861\n",
      "Epoch 74/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2861\n",
      "Epoch 75/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2809\n",
      "Epoch 76/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2806\n",
      "Epoch 77/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2852\n",
      "Epoch 78/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2803\n",
      "Epoch 79/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2835\n",
      "Epoch 80/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2805\n",
      "Epoch 81/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2794\n",
      "Epoch 82/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2791\n",
      "Epoch 83/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2822\n",
      "Epoch 84/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2796\n",
      "Epoch 85/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2797\n",
      "Epoch 86/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2764\n",
      "Epoch 87/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2767\n",
      "Epoch 88/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2775\n",
      "Epoch 89/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2785\n",
      "Epoch 90/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2791\n",
      "Epoch 91/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2751\n",
      "Epoch 92/100\n",
      "396/396 [==============================] - 2s 6ms/step - loss: 0.2762\n",
      "Epoch 93/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2730\n",
      "Epoch 94/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2744\n",
      "Epoch 95/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2800\n",
      "Epoch 96/100\n",
      "396/396 [==============================] - 2s 6ms/step - loss: 0.2735\n",
      "Epoch 97/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2749\n",
      "Epoch 98/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2753\n",
      "Epoch 99/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2776\n",
      "Epoch 100/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.2766\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.2844\n",
      "99/99 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.7661927330173776\n"
     ]
    }
   ],
   "source": [
    "quali_model = create_classification_model(num_features, (64, 32), 'relu', 0.1)\n",
    "quali_model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "accuracy = quali_model.evaluate(X_test, y_test)\n",
    "predictions = quali_model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_verstappen 0.83\n",
      "alexander_albon 0.71\n",
      "sergio_perez 0.54\n",
      "carlos_sainz 0.53\n",
      "lewis_hamilton 0.42\n",
      "fernando_alonso 0.33\n",
      "charles_leclerc 0.29\n",
      "logan_sargeant 0.27\n",
      "pierre_gasly 0.23\n",
      "george_russell 0.15\n",
      "lando_norris 0.11\n",
      "oscar_piastri 0.11\n",
      "lance_stroll 0.07\n",
      "nico_hulkenberg 0.01\n",
      "esteban_ocon 0.01\n",
      "valtteri_bottas 0.00\n",
      "kevin_magnussen 0.00\n",
      "nyck_de_vries 0.00\n",
      "zhou_guanyu 0.00\n",
      "yuki_tsunoda 0.00\n"
     ]
    }
   ],
   "source": [
    "results_quali = get_race_results_with_fp(driver_team_mapping, 2023, 10, 'Great Britain', 'cloudy', X_test, quali_model, fps)\n",
    "arr_quali = []\n",
    "\n",
    "for key, val in results_quali.items():\n",
    "    arr_quali.append((key,\"{:.2f}\".format(float(val))))\n",
    "\n",
    "\n",
    "for item in arr_quali:\n",
    "    print(item[0], item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fastest Lap Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (12659, 416) (12659,)\n",
      "Testing data shape: (3165, 416) (3165,)\n"
     ]
    }
   ],
   "source": [
    "fl_data = full_data.iloc[:]\n",
    "fl_data[\"in_top_5\"] = fl_data['fastest_lap_position'].apply(lambda x: 1 if x<=5 else 0)\n",
    "fl_data = fl_data.drop([\"grid_position\", \"has_fastest_lap\",\"race_laps_completed\",\"points\", \"fastest_lap_position\", \"race_finishing_position\"], axis = 1)\n",
    "\n",
    "# 2021: 14744\n",
    "\n",
    "X = fl_data.drop('in_top_5', axis=1)  \n",
    "y = fl_data['in_top_5']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n",
    "num_features = X_train.shape[1]\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "396/396 [==============================] - 3s 4ms/step - loss: 3.5001\n",
      "Epoch 2/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.4474\n",
      "Epoch 3/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4346\n",
      "Epoch 4/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4298\n",
      "Epoch 5/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4265\n",
      "Epoch 6/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4183\n",
      "Epoch 7/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.4241\n",
      "Epoch 8/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4335\n",
      "Epoch 9/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.4201\n",
      "Epoch 10/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4102\n",
      "Epoch 11/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.4049\n",
      "Epoch 12/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3992\n",
      "Epoch 13/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3984\n",
      "Epoch 14/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3938\n",
      "Epoch 15/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3881\n",
      "Epoch 16/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3898\n",
      "Epoch 17/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3899\n",
      "Epoch 18/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3854\n",
      "Epoch 19/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3854\n",
      "Epoch 20/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3853\n",
      "Epoch 21/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3862\n",
      "Epoch 22/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3847\n",
      "Epoch 23/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3837\n",
      "Epoch 24/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3820\n",
      "Epoch 25/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3814\n",
      "Epoch 26/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3884\n",
      "Epoch 27/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3765\n",
      "Epoch 28/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3753\n",
      "Epoch 29/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3769\n",
      "Epoch 30/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3780\n",
      "Epoch 31/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3794\n",
      "Epoch 32/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3767\n",
      "Epoch 33/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3748\n",
      "Epoch 34/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3745\n",
      "Epoch 35/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3767\n",
      "Epoch 36/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3699\n",
      "Epoch 37/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3713\n",
      "Epoch 38/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3766\n",
      "Epoch 39/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3721\n",
      "Epoch 40/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3748\n",
      "Epoch 41/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3669\n",
      "Epoch 42/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3716\n",
      "Epoch 43/100\n",
      "396/396 [==============================] - 2s 6ms/step - loss: 0.3656\n",
      "Epoch 44/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3654\n",
      "Epoch 45/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3695\n",
      "Epoch 46/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3731\n",
      "Epoch 47/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3675\n",
      "Epoch 48/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3753\n",
      "Epoch 49/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3671\n",
      "Epoch 50/100\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.3686\n",
      "Epoch 51/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3652\n",
      "Epoch 52/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3669\n",
      "Epoch 53/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3663\n",
      "Epoch 54/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3657\n",
      "Epoch 55/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3636\n",
      "Epoch 56/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3639\n",
      "Epoch 57/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3655\n",
      "Epoch 58/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3604\n",
      "Epoch 59/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3650\n",
      "Epoch 60/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3613\n",
      "Epoch 61/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3590\n",
      "Epoch 62/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3611\n",
      "Epoch 63/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3581\n",
      "Epoch 64/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3603\n",
      "Epoch 65/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3646\n",
      "Epoch 66/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3579\n",
      "Epoch 67/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3542\n",
      "Epoch 68/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3553\n",
      "Epoch 69/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3560\n",
      "Epoch 70/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3613\n",
      "Epoch 71/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3564\n",
      "Epoch 72/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3548\n",
      "Epoch 73/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3554\n",
      "Epoch 74/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3564\n",
      "Epoch 75/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3523\n",
      "Epoch 76/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3566\n",
      "Epoch 77/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3560\n",
      "Epoch 78/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3518\n",
      "Epoch 79/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3540\n",
      "Epoch 80/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3549\n",
      "Epoch 81/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3534\n",
      "Epoch 82/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3527\n",
      "Epoch 83/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3551\n",
      "Epoch 84/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3564\n",
      "Epoch 85/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3550\n",
      "Epoch 86/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3517\n",
      "Epoch 87/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3506\n",
      "Epoch 88/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3488\n",
      "Epoch 89/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3523\n",
      "Epoch 90/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3503\n",
      "Epoch 91/100\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.3530\n",
      "Epoch 92/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3507\n",
      "Epoch 93/100\n",
      "396/396 [==============================] - 2s 6ms/step - loss: 0.3514\n",
      "Epoch 94/100\n",
      "396/396 [==============================] - 2s 6ms/step - loss: 0.3509\n",
      "Epoch 95/100\n",
      "396/396 [==============================] - 3s 8ms/step - loss: 0.3489\n",
      "Epoch 96/100\n",
      "396/396 [==============================] - 3s 6ms/step - loss: 0.3489\n",
      "Epoch 97/100\n",
      "396/396 [==============================] - 2s 6ms/step - loss: 0.3484\n",
      "Epoch 98/100\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 0.3515\n",
      "Epoch 99/100\n",
      "396/396 [==============================] - 2s 6ms/step - loss: 0.3504\n",
      "Epoch 100/100\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3476\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.4017\n",
      "99/99 [==============================] - 1s 5ms/step\n",
      "Accuracy: 0.7772511848341233\n"
     ]
    }
   ],
   "source": [
    "fl_model = create_classification_model(num_features, (64, 32), 'relu', 0.1)\n",
    "fl_model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "accuracy = fl_model.evaluate(X_test, y_test)\n",
    "predictions = fl_model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_verstappen 0.69\n",
      "alexander_albon 0.52\n",
      "sergio_perez 0.49\n",
      "lewis_hamilton 0.24\n",
      "carlos_sainz 0.22\n",
      "logan_sargeant 0.17\n",
      "fernando_alonso 0.13\n",
      "george_russell 0.11\n",
      "charles_leclerc 0.09\n",
      "pierre_gasly 0.06\n",
      "lando_norris 0.06\n",
      "oscar_piastri 0.05\n",
      "lance_stroll 0.02\n",
      "yuki_tsunoda 0.01\n",
      "zhou_guanyu 0.01\n",
      "nico_hulkenberg 0.01\n",
      "valtteri_bottas 0.00\n",
      "kevin_magnussen 0.00\n",
      "nyck_de_vries 0.00\n",
      "esteban_ocon 0.00\n"
     ]
    }
   ],
   "source": [
    "results_fl = get_race_results_with_fp(driver_team_mapping, 2023, 10, 'Great Britain', 'cloudy', X_test, fl_model, fps)\n",
    "arr_fl = []\n",
    "\n",
    "for key, val in results_fl.items():\n",
    "    arr_fl.append((key,\"{:.2f}\".format(float(val))))\n",
    "\n",
    "\n",
    "for item in arr_fl:\n",
    "    print(item[0], item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RACE  [('max_verstappen', '0.78'), ('alexander_albon', '0.70'), ('carlos_sainz', '0.66'), ('lewis_hamilton', '0.63'), ('sergio_perez', '0.63'), ('fernando_alonso', '0.51'), ('charles_leclerc', '0.44'), ('george_russell', '0.43'), ('pierre_gasly', '0.30'), ('logan_sargeant', '0.29'), ('oscar_piastri', '0.23'), ('lando_norris', '0.22'), ('lance_stroll', '0.12'), ('esteban_ocon', '0.03'), ('valtteri_bottas', '0.02'), ('nico_hulkenberg', '0.01'), ('nyck_de_vries', '0.01'), ('yuki_tsunoda', '0.01'), ('kevin_magnussen', '0.00'), ('zhou_guanyu', '0.00')]\n",
      "........................\n",
      "QUALI [('max_verstappen', '0.83'), ('alexander_albon', '0.71'), ('sergio_perez', '0.54'), ('carlos_sainz', '0.53'), ('lewis_hamilton', '0.42'), ('fernando_alonso', '0.33'), ('charles_leclerc', '0.29'), ('logan_sargeant', '0.27'), ('pierre_gasly', '0.23'), ('george_russell', '0.15'), ('lando_norris', '0.11'), ('oscar_piastri', '0.11'), ('lance_stroll', '0.07'), ('nico_hulkenberg', '0.01'), ('esteban_ocon', '0.01'), ('valtteri_bottas', '0.00'), ('kevin_magnussen', '0.00'), ('nyck_de_vries', '0.00'), ('zhou_guanyu', '0.00'), ('yuki_tsunoda', '0.00')]\n",
      "........................\n",
      "F_LAP [('max_verstappen', '0.69'), ('alexander_albon', '0.52'), ('sergio_perez', '0.49'), ('lewis_hamilton', '0.24'), ('carlos_sainz', '0.22'), ('logan_sargeant', '0.17'), ('fernando_alonso', '0.13'), ('george_russell', '0.11'), ('charles_leclerc', '0.09'), ('pierre_gasly', '0.06'), ('lando_norris', '0.06'), ('oscar_piastri', '0.05'), ('lance_stroll', '0.02'), ('yuki_tsunoda', '0.01'), ('zhou_guanyu', '0.01'), ('nico_hulkenberg', '0.01'), ('valtteri_bottas', '0.00'), ('kevin_magnussen', '0.00'), ('nyck_de_vries', '0.00'), ('esteban_ocon', '0.00')]\n"
     ]
    }
   ],
   "source": [
    "print(\"RACE \", arr_race)\n",
    "print(\"........................\")\n",
    "print(\"QUALI\", arr_quali)\n",
    "print(\"........................\")\n",
    "print(\"F_LAP\", arr_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowjs\n",
      "  Using cached tensorflowjs-4.9.0-py3-none-any.whl (89 kB)\n",
      "Collecting tensorflow-decision-forests>=1.3.0\n",
      "  Using cached tensorflow_decision_forests-1.5.0-cp310-cp310-macosx_10_15_x86_64.whl (12.3 MB)\n",
      "Collecting importlib_resources>=5.9.0\n",
      "  Using cached importlib_resources-6.0.0-py3-none-any.whl (31 kB)\n",
      "Collecting jax>=0.3.16\n",
      "  Using cached jax-0.4.13-py3-none-any.whl\n",
      "Collecting tensorflow-hub>=0.13.0\n",
      "  Using cached tensorflow_hub-0.14.0-py2.py3-none-any.whl (90 kB)\n",
      "Collecting packaging~=20.9\n",
      "  Using cached packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: six<2,>=1.12.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflowjs) (1.16.0)\n",
      "Requirement already satisfied: tensorflow<3,>=2.12.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflowjs) (2.13.0)\n",
      "Collecting flax<0.6.3,>=0.6.2\n",
      "  Using cached flax-0.6.2-py3-none-any.whl (189 kB)\n",
      "Requirement already satisfied: numpy>=1.12 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (1.24.3)\n",
      "Collecting rich>=11.1\n",
      "  Using cached rich-13.4.2-py3-none-any.whl (239 kB)\n",
      "Collecting tensorstore\n",
      "  Using cached tensorstore-0.1.40-cp310-cp310-macosx_10_14_x86_64.whl (13.8 MB)\n",
      "Collecting optax\n",
      "  Using cached optax-0.1.5-py3-none-any.whl (164 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (4.5.0)\n",
      "Collecting PyYAML>=5.4.1\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-macosx_10_9_x86_64.whl (189 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.4/189.4 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting msgpack\n",
      "  Using cached msgpack-1.0.5-cp310-cp310-macosx_10_9_x86_64.whl (74 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.2-cp310-cp310-macosx_10_12_x86_64.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes>=0.1.0\n",
      "  Using cached ml_dtypes-0.2.0-cp310-cp310-macosx_10_9_universal2.whl (1.2 MB)\n",
      "Requirement already satisfied: scipy>=1.7 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from jax>=0.3.16->tensorflowjs) (1.11.1)\n",
      "Requirement already satisfied: opt-einsum in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from jax>=0.3.16->tensorflowjs) (3.3.0)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Downloading pyparsing-3.1.0-py3-none-any.whl (102 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (3.9.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.32.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (23.5.26)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.13.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (16.0.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (4.23.4)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.4.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.13.0)\n",
      "Requirement already satisfied: setuptools in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (58.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.56.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.3.0)\n",
      "Collecting wurlitzer\n",
      "  Using cached wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: pandas in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow-decision-forests>=1.3.0->tensorflowjs) (2.0.3)\n",
      "Requirement already satisfied: wheel in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorflow-decision-forests>=1.3.0->tensorflowjs) (0.40.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (2.15.1)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (0.7.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.3.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (3.4.3)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.0-cp310-cp310-macosx_10_9_x86_64.whl (243 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.6/243.6 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing>=2.0.2\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-10.0.0-cp310-cp310-macosx_10_10_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-macosx_10_9_x86_64.whl (65 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (2.8.2)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.41.0-cp310-cp310-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting chex>=0.1.5\n",
      "  Using cached chex-0.1.82-py3-none-any.whl (94 kB)\n",
      "Collecting jaxlib>=0.1.37\n",
      "  Using cached jaxlib-0.4.13-cp310-cp310-macosx_10_14_x86_64.whl (75.0 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from pandas->tensorflow-decision-forests>=1.3.0->tensorflowjs) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from pandas->tensorflow-decision-forests>=1.3.0->tensorflowjs) (2023.3)\n",
      "Collecting toolz>=0.9.0\n",
      "  Using cached toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "Collecting chex>=0.1.5\n",
      "  Using cached chex-0.1.81-py3-none-any.whl (94 kB)\n",
      "Collecting dm-tree>=0.1.5\n",
      "  Using cached dm_tree-0.1.8-cp310-cp310-macosx_10_9_x86_64.whl (115 kB)\n",
      "Collecting chex>=0.1.5\n",
      "  Using cached chex-0.1.7-py3-none-any.whl (89 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (1.26.16)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (1.3.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (3.2.2)\n",
      "Installing collected packages: msgpack, dm-tree, wurlitzer, toolz, tensorstore, tensorflow-hub, PyYAML, pyparsing, pillow, ml-dtypes, mdurl, kiwisolver, importlib_resources, fonttools, cycler, contourpy, packaging, markdown-it-py, jaxlib, jax, rich, matplotlib, chex, optax, flax, tensorflow-decision-forests, tensorflowjs\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "Successfully installed PyYAML-6.0.1 chex-0.1.7 contourpy-1.1.0 cycler-0.11.0 dm-tree-0.1.8 flax-0.6.2 fonttools-4.41.0 importlib_resources-6.0.0 jax-0.4.13 jaxlib-0.4.13 kiwisolver-1.4.4 markdown-it-py-3.0.0 matplotlib-3.7.2 mdurl-0.1.2 ml-dtypes-0.2.0 msgpack-1.0.5 optax-0.1.5 packaging-20.9 pillow-10.0.0 pyparsing-3.0.9 rich-13.4.2 tensorflow-decision-forests-1.5.0 tensorflow-hub-0.14.0 tensorflowjs-4.9.0 tensorstore-0.1.40 toolz-0.12.0 wurlitzer-3.0.3\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2 is available.\n",
      "You should consider upgrading via the '/Users/anirudhkrishna/GitHub/FormulaData/formulavenv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfjs.converters.save_keras_model(race_model, \"/Users/anirudhkrishna/GitHub/FormulaData/data-modelling/race_model/\")\n",
    "# tfjs.converters.save_keras_model(quali_model, \"/Users/anirudhkrishna/GitHub/FormulaData/data-modelling/quali_model/\")\n",
    "# tfjs.converters.save_keras_model(fl_model, \"/Users/anirudhkrishna/GitHub/FormulaData/data-modelling/fl_model/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anirudhkrishna/GitHub/FormulaData/formulavenv/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# /Users/anirudhkrishna/GitHub/FormulaData/api/\n",
    "\n",
    "race_model.save(\"/Users/anirudhkrishna/GitHub/FormulaData/api/race_model.h5\")\n",
    "quali_model.save(\"/Users/anirudhkrishna/GitHub/FormulaData/api/quali_model.h5\")\n",
    "fl_model.save(\"/Users/anirudhkrishna/GitHub/FormulaData/api/fl_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.iloc[-20:].to_csv(\"/Users/anirudhkrishna/GitHub/FormulaData/api/sample_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "formulakernel",
   "language": "python",
   "name": "formulakernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
